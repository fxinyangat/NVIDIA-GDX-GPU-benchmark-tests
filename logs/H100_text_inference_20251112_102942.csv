model,platform,batch_size,num_samples,runtime_s,throughput,gpu_name,gpu_util_mean,gpu_util_max,memory_used_mb_peak,memory_percent_peak,memory_total_mb,temperature_c_mean,temperature_c_max,power_draw_w_mean,power_draw_w_max,energy_consumed_wh,timestamp,tokens_per_second,total_tokens,max_new_tokens,inference_engine
meta-llama/Llama-3.2-3B-Instruct,H100,1,1000,45.75148153305054,21.85721568989208,NVIDIA RTX 6000 Ada Generation,89.86813186813187,100,44387.625,90.3289072039072,49140.0,81.95604395604396,84,280.45861538461537,299.751,3.528084822254782,2025-11-12T10:30:45.711656,4815.100902051846,220298,512,vllm
