{
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "batch_sizes": [
    1,
    4,
    8,
    16
  ],
  "max_new_tokens": 512,
  "num_samples": 1000,
  "use_vllm": true,
  "platform": "H100"
}