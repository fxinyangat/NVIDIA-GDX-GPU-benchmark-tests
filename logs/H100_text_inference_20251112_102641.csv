model,platform,batch_size,num_samples,runtime_s,throughput,gpu_name,gpu_util_mean,gpu_util_max,memory_used_mb_peak,memory_percent_peak,memory_total_mb,temperature_c_mean,temperature_c_max,power_draw_w_mean,power_draw_w_max,energy_consumed_wh,timestamp,tokens_per_second,total_tokens,max_new_tokens,inference_engine
meta-llama/Llama-3.1-8B-Instruct,H100,1,1000,153.3279767036438,6.521966972360337,NVIDIA RTX 6000 Ada Generation,94.19672131147541,100,44826.4375,91.22189153439153,49140.0,81.41967213114754,88,290.96578360655735,303.618,12.357533458776098,2025-11-12T10:29:42.003431,3284.47561121461,503602,512,vllm
